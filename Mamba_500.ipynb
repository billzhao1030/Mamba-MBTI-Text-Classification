{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billzhao1030/Mamba-MBTI-Text-Classification/blob/main/Mamba_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DLmT-KRPs6S",
        "outputId": "656dfa68-2bf7-471e-cdfb-53d8ffdb2035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-SYjbUD7csw",
        "outputId": "17b8e852-980b-454f-d0ea-0a286c6e45e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/zeyadkhalid/mbti-personality-types-500-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123M/123M [00:01<00:00, 122MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"zeyadkhalid/mbti-personality-types-500-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eaVOI0K8lo7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1/MBTI 500.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1862GKo5Arj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from dataclasses import dataclass , field , asdict\n",
        "\n",
        "@dataclass\n",
        "class MambaConfig():\n",
        "    d_model: int = 2560\n",
        "    d_intermediate: int = 0\n",
        "    n_layer: int = 64\n",
        "    vocab_size: int = 50277\n",
        "    ssm_cfg: dict = field(default_factory=dict)\n",
        "    attn_layer_idx: list = field(default_factory=list)\n",
        "    attn_cfg: dict = field(default_factory=dict)\n",
        "    rms_norm: bool = True\n",
        "    residual_in_fp32: bool = True\n",
        "    fused_add_norm: bool = True\n",
        "    pad_vocab_size_multiple:int = 8\n",
        "    tie_embeddings: bool = True\n",
        "\n",
        "    def to_json_string(self):\n",
        "        return json.dumps(asdict(self))\n",
        "\n",
        "    def to_dict(self):\n",
        "        return asdict(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfFxKBsh5tiY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MambaClassificationHead(nn.Module):\n",
        "    def __init__(self, d_model, num_classes=16, **kwargs):\n",
        "        super(MambaClassificationHead, self).__init__()\n",
        "\n",
        "        # Use a linear layer to perform classification based on the input with size d_model and the number of classes to classify num_classes.\n",
        "        self.classification_head = nn.Linear(d_model, num_classes, **kwargs)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        return self.classification_head(hidden_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUt1gNlLTwGO",
        "outputId": "950515f4-c788-41e7-fb02-088aac791482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mamba_ssm\n",
            "  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.4.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (24.1)\n",
            "Collecting ninja (from mamba_ssm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (3.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (4.44.2)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba_ssm) (12.6.77)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba_ssm) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba_ssm) (1.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mamba_ssm\n",
            "  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba_ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323988104 sha256=6b082468a6abb6f6bc50c99263f17c6c7f5a2e8f6b275ed7998b81fb25279229\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n",
            "Successfully built mamba_ssm\n",
            "Installing collected packages: ninja, xxhash, dill, multiprocess, mamba_ssm, datasets, evaluate\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 evaluate-0.4.3 mamba_ssm-2.2.2 multiprocess-0.70.16 ninja-1.11.1.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch==2.4.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "# torch.__version__\n",
        "!pip install mamba_ssm evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58vTYfYY5xaP",
        "outputId": "b98e648c-f170-48a4-f309-d1e98cc3db7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout, *args):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout, *args):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
        "from mamba_ssm.utils.hf import load_config_hf,load_state_dict_hf\n",
        "from collections import namedtuple\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class MambaTextClassification(MambaLMHeadModel):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: MambaConfig,\n",
        "        initializer_cfg = None,\n",
        "        device = None,\n",
        "        dtype = None,\n",
        "    ) -> None:\n",
        "        super().__init__(config, initializer_cfg, device, dtype)\n",
        "\n",
        "        # Create a classification head using MambaClassificationHead with input size of d_model and number of classes 2.\n",
        "        self.classification_head = MambaClassificationHead(d_model=config.d_model, num_classes=16)\n",
        "\n",
        "        del self.lm_head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask = None, labels = None):\n",
        "        # Pass input_ids through the backbone model to receive hidden_states.\n",
        "        hidden_states = self.backbone(input_ids)\n",
        "\n",
        "        # Take the mean of hidden_states along the second dimension to create a representative [CLS] feature.\n",
        "        mean_hidden_states = hidden_states.mean(dim = 1)\n",
        "\n",
        "        # Pass mean_hidden_states through the classification head to get logits.\n",
        "        logits = self.classification_head(mean_hidden_states)\n",
        "\n",
        "        if labels is None:\n",
        "            ClassificationOuptput = namedtuple(\"ClassificationOutput\", [\"logits\"])\n",
        "            return ClassificationOutput(logits = logits)\n",
        "        else:\n",
        "            ClassificationOutput = namedtuple(\"ClassificationOutput\", [\"loss\", \"logits\"])\n",
        "\n",
        "            # Use CrossEntropyLoss loss function to compute the loss.\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "            return ClassificationOutput(loss = loss, logits = logits)\n",
        "    def predict(self, text, tokenizer, id2label = None):\n",
        "        input_ids = torch.tensor(tokenizer(text)['input_ids'], device = \"cuda\")[None]\n",
        "        with torch.no_grad():\n",
        "            logits = self.forward(input_ids).logits[0]\n",
        "            label = np.argmax(logits.cpu().numpy())\n",
        "\n",
        "        if id2label is not None:\n",
        "            return id2label[label]\n",
        "        else:\n",
        "            return label\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name, device = None, dtype = None, **kwargs):\n",
        "        # Load the configuration from the pre-trained model.\n",
        "        config_data = load_config_hf(pretrained_model_name)\n",
        "        config = MambaConfig(**config_data)\n",
        "\n",
        "        # Initialize the model from the configuration and move it to the desired device and data type.\n",
        "        model = cls(config, device = device, dtype = dtype, **kwargs)\n",
        "\n",
        "        # Load the state of the pre-trained model.\n",
        "        model_state_dict = load_state_dict_hf(pretrained_model_name, device = device, dtype = dtype)\n",
        "        model.load_state_dict(model_state_dict , strict=False)\n",
        "\n",
        "        # Print the newly initialized embedding parameters.\n",
        "        print (\" Newly initialized embedding :\",\n",
        "              set(model.state_dict().keys()) - set(model_state_dict.keys())\n",
        "        )\n",
        "\n",
        "        return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFcEpGcH51Gx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from transformers import Trainer\n",
        "import torch\n",
        "\n",
        "# Define a class MambaTrainer inheriting from the Trainer class.\n",
        "class MambaTrainer(Trainer):\n",
        "    # Define a function compute_loss to compute the loss during training.\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        # Get the input_ids and labels values from inputs.\n",
        "        input_ids = inputs.pop(\"input_ids\")\n",
        "        labels = inputs.pop('labels')\n",
        "\n",
        "        # Call the forward function of the model with input_ids and labels to get the results.\n",
        "        outputs = model(input_ids=input_ids , labels=labels)\n",
        "\n",
        "        # Get the loss value from the model's outputs.\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Return both loss and outputs if return_outputs is True, otherwise only return loss.\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def save_model(self, output_dir = None, _internal_call = False):\n",
        "        # Check if the output directory is not specified, use the default directory from the 'args' argument.\n",
        "        if output_dir is None:\n",
        "            output_dir = self.args.output_dir\n",
        "\n",
        "        # If the output directory does not exist, create it.\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Save the PyTorch model's state to the 'pytorch_model.bin' file in the output directory.\n",
        "        torch.save(self.model.state_dict(), f\"{output_dir}/pytorch_model.bin\")\n",
        "\n",
        "        # Save the tokenizer's state to the output directory.\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Save the model's configuration to the 'config.json' file in the output directory.\n",
        "        with open(f'{output_dir}/config.json', 'w') as f:\n",
        "            json.dump(self.model.config.to_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYbWT8Aw6gqv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# Load the \"accuracy\" module from the evaluate library.\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Create a preprocessing function to encode text and truncate strings longer than the maximum input token length.\n",
        "def preprocess_function(tokenizer, examples):\n",
        "    samples = tokenizer(examples[\"text\"], truncation=True)\n",
        "    samples.pop('attention_mask')\n",
        "    return samples\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Get the index of the class with the highest probability in predictions.\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Use the \"accuracy\" module to compute accuracy based on predictions and labels.\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "d252498f4a074775aedbcca299429b0b",
            "d222a10ba81b40cca476931e82db2fd4",
            "1634c67f7a214b2984e40213d86b5387",
            "f89a2aeda3024e9eb4ec87b2136f09a7",
            "c010f486364f4aacabe26f4fa5003ba7",
            "7769c70a99f141ebb8bd0a51e7bca530",
            "f04aeca0d2ba408aab00f32898b37eec",
            "a9fab464bfb045759782600ef026281c",
            "af711fe73c564098b6990fc413f4ebb2",
            "b117cb1b79324a0a971b4f41bdecb5bf",
            "a44d60a3b1db482fa78ed780e2bdff02",
            "2383e8ff08e2484e90c73212ceb64673",
            "775fdcfa7c914fb8bb8fa4ff72fac8ff",
            "88a450a64da44f84b60a7c9febbba9ce",
            "095d0a8c89ba4bbea0aff7abd9f21986",
            "b141e054a4b04bec9a59975ef53fab1f",
            "222baab98f9249c2b217d4c13a4f5a3f",
            "ae3cfca8b9af4cf0a857fd0166220863",
            "a1369be135ab41f8bf227eb46e700ba2",
            "59207ce30d3a4de49e0b6043ff31b2f7",
            "f89400276adf4ae4bd1edc97297fdc52",
            "12abb801b5f14d8694442618296da3c0"
          ]
        },
        "id": "bOMCinQG6n0s",
        "outputId": "4cc6db14-bd93-4276-a196-5f4698714c92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d252498f4a074775aedbcca299429b0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/84853 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2383e8ff08e2484e90c73212ceb64673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21214 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from transformers import Trainer\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Load data\n",
        "# df = pd.read_csv('drive/MyDrive/Methodology/mbti_cleaned.csv')\n",
        "\n",
        "# Create a dictionary to map labels to integers\n",
        "label_to_id = {label: idx for idx, label in enumerate(sorted(df['type'].unique()))}\n",
        "\n",
        "# Perform stratified train-test split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['type'], random_state=42)\n",
        "\n",
        "# Convert DataFrames to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize the text\n",
        "    tokenized_inputs = tokenizer(examples['posts'], truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "    # Map labels from strings to integers using a dictionary\n",
        "    labels = [label_to_id[label] for label in examples['type']]\n",
        "\n",
        "    # Update the tokenized inputs dictionary to include labels\n",
        "    tokenized_inputs['labels'] = labels\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Apply the preprocessing function to both datasets\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "4ddd1f8ed8c141bd83016e2249e7ea22",
            "84b2164a23db45a7b26e04e0aafb94a7",
            "d37070ef7ed44dc8a8c9382f57333cd8",
            "00e006fa908f49f5afaed144fdfd2596",
            "03dc2d0d120e4b639b6e7ba488408ce6",
            "edbfa7c2fcfd4c49a7bc0fe6894f93c7",
            "39c9f04b9da04b898556dfe029757e67",
            "71ed4a07654644de8e570bf1cc440ecd",
            "12dce1a75ad94d48b03a49b2ffff58eb",
            "3d2db649a2d343838ddf608c500707b7",
            "56a9dbfe0ba44c309966519e807226c8",
            "7f57b930c452431b87f644422cfefbe3",
            "ce0d61820f214411b466262f950bc5da",
            "e70eb90aab0a4b96922c646eb944816d"
          ]
        },
        "id": "hoZvchSG97WQ",
        "outputId": "3e4f58a8-7042-4730-ac82-0c91253b7bdf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ddd1f8ed8c141bd83016e2249e7ea22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/utils/hf.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(resolved_archive_file, map_location=mapped_device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Newly initialized embedding : set()\n"
          ]
        }
      ],
      "source": [
        "token = os.getenv(\"HUGGINGFACE_TOKEN\") # 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\n",
        "login(token=token, write_permission=True)\n",
        "\n",
        "# Load the Mamba model from a pretrained model.\n",
        "model = MambaTextClassification.from_pretrained(\"BuduBuduBudu/mamba_mbti_500\") # state-spaces/mamba-130m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "JvxtbZ8FQrl9",
        "outputId": "d1f52276-19b2-4ddf-81f0-11a5c1859dd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1/wandb/run-20241029_063131-4qxy2cvu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/leh172270-uniadelaide/huggingface/runs/4qxy2cvu' target=\"_blank\">mamba_mbti_500</a></strong> to <a href='https://wandb.ai/leh172270-uniadelaide/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/leh172270-uniadelaide/huggingface' target=\"_blank\">https://wandb.ai/leh172270-uniadelaide/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/leh172270-uniadelaide/huggingface/runs/4qxy2cvu' target=\"_blank\">https://wandb.ai/leh172270-uniadelaide/huggingface/runs/4qxy2cvu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='42428' max='42428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [42428/42428 1:46:04, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>4243</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>0.650957</td>\n",
              "      <td>0.796267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8486</td>\n",
              "      <td>0.870800</td>\n",
              "      <td>0.638729</td>\n",
              "      <td>0.812529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12729</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>0.582085</td>\n",
              "      <td>0.831149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16972</td>\n",
              "      <td>0.059600</td>\n",
              "      <td>0.517810</td>\n",
              "      <td>0.848213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21215</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.487450</td>\n",
              "      <td>0.853682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25458</td>\n",
              "      <td>0.017700</td>\n",
              "      <td>0.600130</td>\n",
              "      <td>0.852503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.639197</td>\n",
              "      <td>0.852079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33944</td>\n",
              "      <td>0.102200</td>\n",
              "      <td>0.650520</td>\n",
              "      <td>0.855614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38187</td>\n",
              "      <td>0.358500</td>\n",
              "      <td>0.634669</td>\n",
              "      <td>0.856604</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=42428, training_loss=0.47469002701040913, metrics={'train_runtime': 6398.6102, 'train_samples_per_second': 26.522, 'train_steps_per_second': 6.631, 'total_flos': 0.0, 'train_loss': 0.47469002701040913, 'epoch': 2.0})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define training arguments in the TrainingArguments class.\n",
        "# More details about supported parameters can be found at: https://huggingface.co/docs/transformers/main_classes/trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"mamba_mbti_500\",  # Output folder name\n",
        "    learning_rate=5e-5, #4e-7\n",
        "    per_device_train_batch_size=4,  # Number of training samples per device\n",
        "    per_device_eval_batch_size=16,  # Number of evaluation samples per device\n",
        "    num_train_epochs=2,  # Number of training epochs\n",
        "    warmup_ratio=0.01,  # Ratio of increasing LR during warmup\n",
        "    lr_scheduler_type=\"cosine\",  # Type of scheduler to decrease LR\n",
        "    report_to=\"wandb\",  # \"wandb\" if you want to log results\n",
        "    evaluation_strategy=\"steps\",  # Determine the metric for evaluation after each step\n",
        "    eval_steps=0.1,  # Number of steps between evaluation batches\n",
        "    save_strategy=\"steps\",  # Determine when to save checkpoints\n",
        "    save_steps=0.1,  # Number of steps between saving checkpoints\n",
        "    logging_strategy=\"steps\",  # Determine when to log information\n",
        "    logging_steps=1,  # Number of steps between logging\n",
        "    push_to_hub=True,  # Push the results to the Hub\n",
        "    load_best_model_at_end=True,  # Load the model with the best evaluation result during training\n",
        ")\n",
        "\n",
        "# Initialize the MambaTrainer class to perform the model training process.\n",
        "trainer = MambaTrainer(\n",
        "    model=model,  # Model to train\n",
        "    train_dataset=train_dataset,  # Training data\n",
        "    eval_dataset=test_dataset,  # Evaluation data\n",
        "    tokenizer=tokenizer,  # Tokenizer used to encode data\n",
        "    args=training_args,  # Pre-defined training parameters\n",
        "    compute_metrics=compute_metrics  # Function to calculate performance metrics for evaluation\n",
        ")\n",
        "\n",
        "# Start the training process by calling the train() function on the trainer class.\n",
        "trainer.train()\n",
        "\n",
        "# 788dd3b5a8c1bc23eafad2de4161fe1bcdeb55a7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LHTQuyJjjPlD",
        "outputId": "d5cedf6a-f015-444f-a21e-efb49044e76f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "\n",
        "# Define training arguments - you don't need to set many parameters for evaluation only\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    do_eval=True,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\"  # Avoids unnecessary logging\n",
        ")\n",
        "\n",
        "# Define the Trainer for evaluation\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Run predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HsbA_fqAPrE",
        "outputId": "6026f705-0bc7-475c-c19c-6c81a095d846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.81      0.74      0.77       307\n",
            "        ENFP       0.85      0.83      0.84      1233\n",
            "        ENTJ       0.90      0.81      0.85       591\n",
            "        ENTP       0.86      0.85      0.85      2345\n",
            "        ESFJ       0.71      0.61      0.66        36\n",
            "        ESFP       0.71      0.49      0.58        72\n",
            "        ESTJ       0.88      0.76      0.82        96\n",
            "        ESTP       0.95      0.93      0.94       397\n",
            "        INFJ       0.86      0.87      0.87      2993\n",
            "        INFP       0.83      0.86      0.84      2427\n",
            "        INTJ       0.87      0.88      0.87      4486\n",
            "        INTP       0.86      0.88      0.87      4992\n",
            "        ISFJ       0.76      0.67      0.71       130\n",
            "        ISFP       0.71      0.65      0.67       175\n",
            "        ISTJ       0.75      0.69      0.72       249\n",
            "        ISTP       0.88      0.83      0.85       685\n",
            "\n",
            "    accuracy                           0.86     21214\n",
            "   macro avg       0.82      0.77      0.80     21214\n",
            "weighted avg       0.86      0.86      0.86     21214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "true_labels = test_dataset['labels']\n",
        "\n",
        "print(classification_report(true_labels, preds, target_names=list(label_to_id.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPbHTG8t330Q",
        "outputId": "e5b1e4df-de5a-4962-c671-fccc5268a99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension Accuracies: {'I/E': 0.9422079758649948, 'S/N': 0.9741680022626568, 'T/F': 0.9531912887715659, 'P/J': 0.91788441595173}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create reverse mapping from integers to MBTI types\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "# Convert integer labels back to MBTI string labels\n",
        "true_labels = [id_to_label[label.item()] for label in test_dataset['labels']]\n",
        "pred_labels = [id_to_label[pred] for pred in preds]\n",
        "\n",
        "# Define a helper function to get accuracy for each dimension\n",
        "def dimension_accuracy(true_mbti, pred_mbti, index):\n",
        "    true_dim = [mbti[index] for mbti in true_mbti]\n",
        "    pred_dim = [mbti[index] for mbti in pred_mbti]\n",
        "    return accuracy_score(true_dim, pred_dim)\n",
        "\n",
        "# Calculate accuracies for each dimension\n",
        "dimension_labels = ['I/E', 'S/N', 'T/F', 'P/J']\n",
        "dimension_accuracies = {}\n",
        "\n",
        "for i, dim_label in enumerate(dimension_labels):\n",
        "    accuracy = dimension_accuracy(true_labels, pred_labels, i)\n",
        "    dimension_accuracies[dim_label] = accuracy\n",
        "\n",
        "print(\"Dimension Accuracies:\", dimension_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J-_1dsH35iS",
        "outputId": "10e13316-b74f-4eb5-dbf4-164333fd24e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Partial Accuracy: 0.9469\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming `pred_labels` and `true_labels` are arrays of predicted and true labels (e.g., MBTI types)\n",
        "# and are already available after using `trainer.predict()`.\n",
        "\n",
        "def compute_partial_accuracy(pred_labels, true_labels):\n",
        "    # Convert the MBTI labels to binary vectors for each dimension\n",
        "    pred_vectors = [mbti_to_vector(label) for label in pred_labels]\n",
        "    true_vectors = [mbti_to_vector(label) for label in true_labels]\n",
        "\n",
        "    # Calculate partial accuracy for each sample\n",
        "    partial_accuracies = []\n",
        "    for pred, true in zip(pred_vectors, true_vectors):\n",
        "        correct_dims = sum(p == t for p, t in zip(pred, true))\n",
        "        partial_accuracy = correct_dims / 4  # Each dimension is worth 0.25\n",
        "        partial_accuracies.append(partial_accuracy)\n",
        "\n",
        "    # Compute the average partial accuracy\n",
        "    avg_partial_accuracy = np.mean(partial_accuracies)\n",
        "    return avg_partial_accuracy\n",
        "\n",
        "# Convert MBTI label to binary vector (e.g., \"INTJ\" -> [1, 0, 1, 0])\n",
        "def mbti_to_vector(label):\n",
        "    return [\n",
        "        1 if label[0] == 'I' else 0,  # I/E\n",
        "        1 if label[1] == 'N' else 0,  # N/S\n",
        "        1 if label[2] == 'T' else 0,  # T/F\n",
        "        1 if label[3] == 'J' else 0   # J/P\n",
        "    ]\n",
        "\n",
        "# Calculate and print the average partial accuracy\n",
        "avg_partial_acc = compute_partial_accuracy(pred_labels, true_labels)\n",
        "print(f\"Average Partial Accuracy: {avg_partial_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "CIr4AKQaFqNw",
        "outputId": "15907edd-a80a-4666-c398-0fae0009385f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11310' max='21214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11310/21214 35:38 < 31:12, 5.29 it/s, Epoch 0.53/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2122</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.654673</td>\n",
              "      <td>0.856510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4244</td>\n",
              "      <td>0.037700</td>\n",
              "      <td>0.668801</td>\n",
              "      <td>0.855426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.683089</td>\n",
              "      <td>0.854624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8488</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.697219</td>\n",
              "      <td>0.854106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10610</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.705398</td>\n",
              "      <td>0.853446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define training arguments in the TrainingArguments class.\n",
        "# More details about supported parameters can be found at: https://huggingface.co/docs/transformers/main_classes/trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"mamba_mbti_500_fine_tune\",  # Output folder name\n",
        "    learning_rate=4e-7, #4e-7\n",
        "    per_device_train_batch_size=4,  # Number of training samples per device\n",
        "    per_device_eval_batch_size=16,  # Number of evaluation samples per device\n",
        "    num_train_epochs=1,  # Number of training epochs\n",
        "    warmup_ratio=0.01,  # Ratio of increasing LR during warmup\n",
        "    lr_scheduler_type=\"cosine\",  # Type of scheduler to decrease LR\n",
        "    report_to=\"wandb\",  # \"wandb\" if you want to log results\n",
        "    evaluation_strategy=\"steps\",  # Determine the metric for evaluation after each step\n",
        "    eval_steps=0.1,  # Number of steps between evaluation batches\n",
        "    save_strategy=\"steps\",  # Determine when to save checkpoints\n",
        "    save_steps=0.1,  # Number of steps between saving checkpoints\n",
        "    logging_strategy=\"steps\",  # Determine when to log information\n",
        "    logging_steps=1,  # Number of steps between logging\n",
        "    push_to_hub=True,  # Push the results to the Hub\n",
        "    load_best_model_at_end=True,  # Load the model with the best evaluation result during training\n",
        ")\n",
        "\n",
        "# Initialize the MambaTrainer class to perform the model training process.\n",
        "trainer = MambaTrainer(\n",
        "    model=model,  # Model to train\n",
        "    train_dataset=train_dataset,  # Training data\n",
        "    eval_dataset=test_dataset,  # Evaluation data\n",
        "    tokenizer=tokenizer,  # Tokenizer used to encode data\n",
        "    args=training_args,  # Pre-defined training parameters\n",
        "    compute_metrics=compute_metrics  # Function to calculate performance metrics for evaluation\n",
        ")\n",
        "\n",
        "# Start the training process by calling the train() function on the trainer class.\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyOUnjzsnJMaVD6DqhSjqPwF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00e006fa908f49f5afaed144fdfd2596": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a9dbfe0ba44c309966519e807226c8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7f57b930c452431b87f644422cfefbe3",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "03dc2d0d120e4b639b6e7ba488408ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0d61820f214411b466262f950bc5da",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e70eb90aab0a4b96922c646eb944816d",
            "value": "Login successful"
          }
        },
        "095d0a8c89ba4bbea0aff7abd9f21986": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89400276adf4ae4bd1edc97297fdc52",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_12abb801b5f14d8694442618296da3c0",
            "value": "â€‡21214/21214â€‡[00:09&lt;00:00,â€‡2069.60â€‡examples/s]"
          }
        },
        "12abb801b5f14d8694442618296da3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12dce1a75ad94d48b03a49b2ffff58eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1634c67f7a214b2984e40213d86b5387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9fab464bfb045759782600ef026281c",
            "max": 84853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af711fe73c564098b6990fc413f4ebb2",
            "value": 84853
          }
        },
        "222baab98f9249c2b217d4c13a4f5a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2383e8ff08e2484e90c73212ceb64673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_775fdcfa7c914fb8bb8fa4ff72fac8ff",
              "IPY_MODEL_88a450a64da44f84b60a7c9febbba9ce",
              "IPY_MODEL_095d0a8c89ba4bbea0aff7abd9f21986"
            ],
            "layout": "IPY_MODEL_b141e054a4b04bec9a59975ef53fab1f"
          }
        },
        "39c9f04b9da04b898556dfe029757e67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2db649a2d343838ddf608c500707b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ddd1f8ed8c141bd83016e2249e7ea22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84b2164a23db45a7b26e04e0aafb94a7",
              "IPY_MODEL_d37070ef7ed44dc8a8c9382f57333cd8",
              "IPY_MODEL_00e006fa908f49f5afaed144fdfd2596",
              "IPY_MODEL_03dc2d0d120e4b639b6e7ba488408ce6"
            ],
            "layout": "IPY_MODEL_edbfa7c2fcfd4c49a7bc0fe6894f93c7"
          }
        },
        "56a9dbfe0ba44c309966519e807226c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59207ce30d3a4de49e0b6043ff31b2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71ed4a07654644de8e570bf1cc440ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775fdcfa7c914fb8bb8fa4ff72fac8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222baab98f9249c2b217d4c13a4f5a3f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ae3cfca8b9af4cf0a857fd0166220863",
            "value": "Map:â€‡100%"
          }
        },
        "7769c70a99f141ebb8bd0a51e7bca530": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f57b930c452431b87f644422cfefbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b2164a23db45a7b26e04e0aafb94a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c9f04b9da04b898556dfe029757e67",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_71ed4a07654644de8e570bf1cc440ecd",
            "value": "Token is valid (permission: write)."
          }
        },
        "88a450a64da44f84b60a7c9febbba9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1369be135ab41f8bf227eb46e700ba2",
            "max": 21214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59207ce30d3a4de49e0b6043ff31b2f7",
            "value": 21214
          }
        },
        "a1369be135ab41f8bf227eb46e700ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44d60a3b1db482fa78ed780e2bdff02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9fab464bfb045759782600ef026281c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3cfca8b9af4cf0a857fd0166220863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af711fe73c564098b6990fc413f4ebb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b117cb1b79324a0a971b4f41bdecb5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b141e054a4b04bec9a59975ef53fab1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c010f486364f4aacabe26f4fa5003ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0d61820f214411b466262f950bc5da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d222a10ba81b40cca476931e82db2fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7769c70a99f141ebb8bd0a51e7bca530",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f04aeca0d2ba408aab00f32898b37eec",
            "value": "Map:â€‡100%"
          }
        },
        "d252498f4a074775aedbcca299429b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d222a10ba81b40cca476931e82db2fd4",
              "IPY_MODEL_1634c67f7a214b2984e40213d86b5387",
              "IPY_MODEL_f89a2aeda3024e9eb4ec87b2136f09a7"
            ],
            "layout": "IPY_MODEL_c010f486364f4aacabe26f4fa5003ba7"
          }
        },
        "d37070ef7ed44dc8a8c9382f57333cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12dce1a75ad94d48b03a49b2ffff58eb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3d2db649a2d343838ddf608c500707b7",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "e70eb90aab0a4b96922c646eb944816d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edbfa7c2fcfd4c49a7bc0fe6894f93c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "f04aeca0d2ba408aab00f32898b37eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89400276adf4ae4bd1edc97297fdc52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89a2aeda3024e9eb4ec87b2136f09a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b117cb1b79324a0a971b4f41bdecb5bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a44d60a3b1db482fa78ed780e2bdff02",
            "value": "â€‡84853/84853â€‡[00:40&lt;00:00,â€‡2095.43â€‡examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}